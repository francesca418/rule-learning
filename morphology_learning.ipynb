{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"morphology_learning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO48SgFBbMaX8w0G7q1fR5i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"OTbVxQy6aGiO"},"source":["!pip install word2vec"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MqqdnQdGJdB-","executionInfo":{"status":"ok","timestamp":1636502480862,"user_tz":300,"elapsed":3442,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"f2564635-5892-491f-cf60-6641abb01e72"},"source":["!pip install pyjarowinkler"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyjarowinkler\n","  Downloading pyjarowinkler-1.8-py2.py3-none-any.whl (5.9 kB)\n","Installing collected packages: pyjarowinkler\n","Successfully installed pyjarowinkler-1.8\n"]}]},{"cell_type":"code","metadata":{"id":"2M3bTnusTWZX"},"source":["# imports\n","import os\n","import sys\n","import re\n","import numpy as np\n","import gensim\n","from gensim.models import Word2Vec\n","from gensim.models import KeyedVectors\n","import gensim.downloader\n","import logging\n","import gzip\n","import json\n","from pyjarowinkler import distance"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2zG1_VlpPcVo"},"source":["logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9DNzmfrO1SSg","executionInfo":{"status":"ok","timestamp":1636494670134,"user_tz":300,"elapsed":125,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"68e77437-4122-4fa7-d3ee-fd88dbe2ff92"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"D9DxandvDO0E"},"source":["# Exploring the Data"]},{"cell_type":"code","metadata":{"id":"eVwhBWZUDI1J"},"source":["# reading in the data file\n","filepath = \"drive/MyDrive/Morphology Learning/\"\n","lines = []\n","with open(os.path.join(filepath, \"childes-input.txt\")) as f:\n","  lines = f.readlines()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X-8gjThcDRol"},"source":["# Pre-Processing the Data"]},{"cell_type":"code","metadata":{"id":"nzk0Ho2tDVBD"},"source":["# strip whitespace, newlines, punctuation, set to lowercase\n","def preprocess_lines(line):\n","  # lowercase\n","  lower = line.lower()\n","  punc = re.sub(r'[^\\w\\s]', '', lower)\n","  # remove whitespace + newlines and convert to tokens\n","  cleaned = punc.strip().split()\n","  return cleaned\n","\n","clean_lines = list(map(preprocess_lines, lines))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iizuiUkZ3_Kd"},"source":["# clean_lines[:20]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"19YWwRVr5Ucz","executionInfo":{"status":"ok","timestamp":1636494700728,"user_tz":300,"elapsed":5019,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"90cd50f8-701c-4e4e-f011-d61c15f7e3df"},"source":["# get some basic stats on the data\n","print(\"Lines: \" + str(len(clean_lines)))\n","token_count = 0\n","unique_words = {}\n","for line in clean_lines:\n","  for word in line:\n","    token_count += 1\n","    if word not in unique_words:\n","      unique_words[word] = 1\n","    else:\n","      unique_words[word] += 1\n","print(\"Tokens: \" + str(token_count))\n","print(\"Unique Tokens: \" + str(len(unique_words)))\n","\n","# dictionary tracking things -> unique_words"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Lines: 2631544\n","Tokens: 11496792\n","Unique Tokens: 42234\n"]}]},{"cell_type":"code","metadata":{"id":"-z-RbCho5rH9"},"source":["# unique_words"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L4hShu5cDVSk"},"source":["# Selecting Similar Words"]},{"cell_type":"code","metadata":{"id":"W_oU37StDYpo"},"source":["# semantics -- train word2vec (or any other representings) on the data\n","# build vocabulary & train the model\n","# can play around with model hyperparameters down the line too -- can continue to train by loading the model and calling train...\n","model = Word2Vec(sentences=clean_lines, sg=1, min_count=1) # using skip-gram, not cbow, default dimension is 100, default epochs is 5 (can increase this)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7awgPH7eUW5","executionInfo":{"status":"ok","timestamp":1636501553145,"user_tz":300,"elapsed":797,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"71298347-9b8f-4c32-a593-bf6d2a16e9ac"},"source":["# save this model\n","model.save(os.path.join(filepath, 'base-word2vec-childes.model'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-11-09 23:45:52,206 : INFO : saving Word2Vec object under drive/MyDrive/Morphology Learning/base-word2vec-childes.model, separately None\n","2021-11-09 23:45:52,208 : INFO : not storing attribute vectors_norm\n","2021-11-09 23:45:52,210 : INFO : not storing attribute cum_table\n","2021-11-09 23:45:52,979 : INFO : saved drive/MyDrive/Morphology Learning/base-word2vec-childes.model\n"]}]},{"cell_type":"code","metadata":{"id":"OAyAhb1AeaWc"},"source":["# download and load a pretrained model -- 300 dimension word2vec embeddings trained on Google news\n","# could function as a kind of control??\n","# google_word2vec_model = gensim.downloader.load('word2vec-google-news-300') \n","# fine tune on the sentences from childes (would this even make any difference?)\n","# google_word2vec_model.train(corpus_iterable=clean_lines)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAFu74clv9nL","executionInfo":{"status":"ok","timestamp":1636501553787,"user_tz":300,"elapsed":646,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"9e60e619-9071-4cc1-899a-363d1d481700"},"source":["# load the saved model\n","model = Word2Vec.load(os.path.join(filepath, 'base-word2vec-childes.model'))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-11-09 23:45:53,004 : INFO : loading Word2Vec object from drive/MyDrive/Morphology Learning/base-word2vec-childes.model\n","2021-11-09 23:45:53,461 : INFO : loading wv recursively from drive/MyDrive/Morphology Learning/base-word2vec-childes.model.wv.* with mmap=None\n","2021-11-09 23:45:53,463 : INFO : setting ignored attribute vectors_norm to None\n","2021-11-09 23:45:53,464 : INFO : loading vocabulary recursively from drive/MyDrive/Morphology Learning/base-word2vec-childes.model.vocabulary.* with mmap=None\n","2021-11-09 23:45:53,472 : INFO : loading trainables recursively from drive/MyDrive/Morphology Learning/base-word2vec-childes.model.trainables.* with mmap=None\n","2021-11-09 23:45:53,474 : INFO : setting ignored attribute cum_table to None\n","2021-11-09 23:45:53,476 : INFO : loaded drive/MyDrive/Morphology Learning/base-word2vec-childes.model\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H00Lm55a-pcU","executionInfo":{"status":"ok","timestamp":1636501558795,"user_tz":300,"elapsed":464,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"8fba6009-717b-43fc-a1a3-33c8c189c3f4"},"source":["word_vectors = model.wv\n","word_vectors.save('childes-word2vec.wordvectors')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["2021-11-09 23:45:58,281 : INFO : saving Word2VecKeyedVectors object under childes-word2vec.wordvectors, separately None\n","2021-11-09 23:45:58,283 : INFO : not storing attribute vectors_norm\n","2021-11-09 23:45:58,557 : INFO : saved childes-word2vec.wordvectors\n"]}]},{"cell_type":"code","metadata":{"id":"xpnOgKgJ_FIY"},"source":["# word_vectors['jump']\n","word_vectors.most_similar('jump', topn=25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-V2V50zkDWo-","executionInfo":{"status":"ok","timestamp":1636501586840,"user_tz":300,"elapsed":157,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"1382e2e5-fba7-4f2a-84e1-20a5b88f4f55"},"source":["len(model.wv.vocab.keys())"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["42234"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"yn1zlPg9BkSK"},"source":["semantic_similarities = {}\n","missed = []\n","count = 0\n","for key in unique_words.keys():\n","  count += 1\n","  #if (count % 1000 == 0):\n","    #print(\"Processed '%d' unique tokens.\" % count)\n","  try:\n","    semantic_similarities[key] = word_vectors.most_similar(key, topn=25)\n","  except:\n","    print(\"Missed '%s'\" % key)\n","    missed.append(key)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"44xnGqrjGyBW"},"source":["with open(os.path.join(filepath, 'childes-semantic-similarities.json'), \"w\") as f:\n","  json.dump(semantic_similarities, f, indent=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W4UF7Fs_HiT6"},"source":["semantic_similarities"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"drVDEamEKyS7","executionInfo":{"status":"ok","timestamp":1636505376767,"user_tz":300,"elapsed":128,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"d063531b-0d77-48ab-c470-8ae7e38d063d"},"source":["semantic_similarities[\"went\"]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('walked', 0.7681492567062378),\n"," ('came', 0.6991715431213379),\n"," ('drove', 0.6915683746337891),\n"," ('took', 0.6682751774787903),\n"," ('rushed', 0.6550699472427368),\n"," ('rode', 0.6549469828605652),\n"," ('ran', 0.6510108709335327),\n"," ('yesterday', 0.6326640844345093),\n"," ('traveled', 0.6226305961608887),\n"," ('go', 0.6135805249214172),\n"," ('crawled', 0.6061288714408875),\n"," ('wayland', 0.6043776273727417),\n"," ('hurried', 0.6028647422790527),\n"," ('followed', 0.5976724624633789),\n"," ('fell', 0.5917340517044067),\n"," ('hiking', 0.586167573928833),\n"," ('visited', 0.5850282311439514),\n"," ('wandered', 0.5827513933181763),\n"," ('chicago', 0.5802407264709473),\n"," ('sawed', 0.5800257921218872),\n"," ('spoke', 0.5792049169540405),\n"," ('saw', 0.5744475722312927),\n"," ('picadilly', 0.5737274885177612),\n"," ('jumped', 0.57276451587677),\n"," ('dashed', 0.5727537870407104)]"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"A0dJLwhklvO1"},"source":["# morphology -- Levenshtein distance (should we consider Jaro-Winkler?)\n","# would only want to do this for words with already similar representations to cut down on the runtime??\n","# could also redo for all words and see if that outputs anything different... -> totally independent processes...\n","def levenshtein(token1, token2):\n","  distances = np.zeros((len(token1) + 1, len(token2) + 1))\n","  for t1 in range(len(token1) + 1):\n","      distances[t1][0] = t1\n","  for t2 in range(len(token2) + 1):\n","      distances[0][t2] = t2 \n","  a = 0\n","  b = 0\n","  c = 0\n","  for t1 in range(1, len(token1) + 1):\n","      for t2 in range(1, len(token2) + 1):\n","          if (token1[t1-1] == token2[t2-1]):\n","              distances[t1][t2] = distances[t1 - 1][t2 - 1]\n","          else:\n","              a = distances[t1][t2 - 1]\n","              b = distances[t1 - 1][t2]\n","              c = distances[t1 - 1][t2 - 1]  \n","              if (a <= b and a <= c):\n","                  distances[t1][t2] = a + 1\n","              elif (b <= a and b <= c):\n","                  distances[t1][t2] = b + 1\n","              else:\n","                  distances[t1][t2] = c + 1\n","  return distances[len(token1)][len(token2)] \n","\n","def calcDictDistance(word, comp_words, numWords):\n","    dictWordDist = []\n","    wordIdx = 0\n","    for comp_word in comp_words: \n","        wordDistance = levenshtein(word, comp_word.strip())\n","        if wordDistance >= 10:\n","            wordDistance = 9\n","        dictWordDist.append(str(int(wordDistance)) + \"-\" + comp_word.strip())\n","        wordIdx = wordIdx + 1\n","    closestWords = []\n","    wordDetails = []\n","    currWordDist = 0\n","    dictWordDist.sort()\n","    #print(dictWordDist)\n","    for i in range(numWords):\n","        currWordDist = dictWordDist[i]\n","        wordDetails = currWordDist.split(\"-\")\n","        closestWords.append(wordDetails[1])\n","    return closestWords  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yKvaeT45JrLm"},"source":["def calcDictDistanceJaro(word, comp_words, numWords):\n","  dictWordDist = []\n","  wordIdx = 0\n","  for comp_word in comp_words: \n","      wordDistance = distance.get_jaro_distance(word, comp_word, winkler=True, scaling=0.1)\n","      wordDistance = levenshtein(word, comp_word.strip())\n","      #if wordDistance >= 10:\n","          #wordDistance = 9\n","      dictWordDist.append(str(int(wordDistance)) + \"-\" + comp_word.strip())\n","      wordIdx = wordIdx + 1\n","  closestWords = []\n","  wordDetails = []\n","  currWordDist = 0\n","  dictWordDist.sort()\n","  #print(dictWordDist)\n","  for i in range(numWords):\n","      currWordDist = dictWordDist[i]\n","      wordDetails = currWordDist.split(\"-\")\n","      closestWords.append(wordDetails[1])\n","  return closestWords"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VAIoNVuIHxTW","executionInfo":{"status":"ok","timestamp":1636502257054,"user_tz":300,"elapsed":110,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"b0cc63d0-5b1f-4957-8e1e-da21e8105be5"},"source":["# test the above edit distance code on one example\n","# semantic_similarities['jump']\n","similar_words = [x[0] for x in semantic_similarities['jump']]\n","# print(similar_words)\n","calcDictDistance(\"jump\", similar_words, 5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['jumps', 'jumpin', 'hop', 'jumping', 'run']"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_K8XoyKbKcwr","executionInfo":{"status":"ok","timestamp":1636502750894,"user_tz":300,"elapsed":127,"user":{"displayName":"Francesca Marini","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13526885581607466268"}},"outputId":"a0d2bb8e-a2d3-4225-b31d-7296e1129500"},"source":["calcDictDistanceJaro(\"jump\", similar_words, 5)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['jumps', 'jumpin', 'hop', 'jumping', 'run']"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"eqA0ZKtv44zC"},"source":["# save similarities to file so that we do not need to re-run this repeatedly\n","word_form_similarities = {}\n","word_form_similarities_jaro = {}\n","count = 0\n","for word in semantic_similarities.keys():\n","  count += 1\n","  #if (count % 1000 == 0):\n","    #print(\"Processed '%d' unique tokens.\" % count)\n","  similar_words = [x[0] for x in semantic_similarities[word]]\n","  word_form_similarities[word] = calcDictDistance(word, similar_words, 10)\n","  word_form_similarities_jaro[word] = calcDictDistanceJaro(word, similar_words, 10)  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXDb_YwrMDM9"},"source":["with open(os.path.join(filepath, 'childes-wordform-similarities.json'), \"w\") as f:\n","  json.dump(word_form_similarities, f, indent=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-3dWzFg2QSGh"},"source":["with open(os.path.join(filepath, 'childes-wordform-similarities-jaro.json'), \"w\") as f:\n","  json.dump(word_form_similarities_jaro, f, indent=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8oSSB7IbOqmL"},"source":["# word_form_similarities"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zcoP99sADZLK"},"source":["# Applying Some Computational Linguistics Techniques"]},{"cell_type":"code","metadata":{"id":"6LPLzPxBDd0V"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GQFCXZbKocyH"},"source":["# Model to Train On Data"]},{"cell_type":"code","metadata":{"id":"Lz65MbXFof1U"},"source":["# based on the paper sent to me -- used to identify morphologically similar tokens\n","# model: https://github.com/cbelth/ATP-morphology\n"],"execution_count":null,"outputs":[]}]}